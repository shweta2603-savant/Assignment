{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q 1.Discuss the scenarios where multithreding is preferable to multiprocessing and scenario where multirocessing is a better choice."
      ],
      "metadata": {
        "id": "UL3KbVPZpO3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice between **multithreading** and **multiprocessing** depends on the nature of the task you're trying to parallelize, the resources required, and the constraints of your system. Here's a detailed breakdown of when each approach is preferable:\n",
        "\n",
        "### When Multithreading is Preferable\n",
        "Multithreading is more suitable for scenarios where the program is **I/O-bound** or where tasks need to share memory and data frequently. It's also appropriate when you need to leverage concurrency without creating separate processes. Here are specific scenarios where multithreading is a better choice:\n",
        "\n",
        "#### 1. **I/O-Bound Tasks (e.g., Web Scraping, File I/O)**\n",
        "   - **Example**: Downloading files from multiple URLs, reading/writing large files, or interacting with databases.\n",
        "   - **Reasoning**: In I/O-bound tasks, threads spend most of their time waiting for external resources (like disk or network) rather than doing heavy computation. While one thread waits for an I/O operation to complete, another thread can proceed with its task. Python's **Global Interpreter Lock (GIL)** doesn't hinder performance in I/O-bound tasks since the GIL is released during I/O operations.\n",
        "\n",
        "#### 2. **Shared Memory Requirement**\n",
        "   - **Example**: Parallelizing tasks that need to frequently read/write to shared data (e.g., a shared cache, database, or logging system).\n",
        "   - **Reasoning**: Threads share the same memory space, so it’s easier to share and modify data between them without having to worry about inter-process communication mechanisms like pipes or queues. This is especially beneficial when you're dealing with large datasets that must be accessed by multiple threads concurrently.\n",
        "\n",
        "#### 3. **Low Overhead and Lightweight**\n",
        "   - **Example**: Running many lightweight tasks that don’t require heavy computation, such as handling multiple user requests in a server or performing simple calculations in parallel.\n",
        "   - **Reasoning**: Creating a thread is generally more lightweight than creating a new process. Threads can share resources like memory, making them less expensive in terms of memory overhead and context-switching costs. For smaller, quick tasks, threading allows for better scalability.\n",
        "\n",
        "#### 4. **Real-Time Systems (to Some Extent)**\n",
        "   - **Example**: A real-time application where certain tasks need to be processed concurrently, like event handling or real-time data streaming.\n",
        "   - **Reasoning**: Since threads are lighter and share memory space, you can achieve low-latency concurrency (though Python’s GIL can be a limiting factor in CPU-bound real-time systems, threading can still be used for non-CPU-bound tasks).\n",
        "\n",
        "### When Multiprocessing is Preferable\n",
        "Multiprocessing is a better choice when the tasks are **CPU-bound** (i.e., they require heavy computation) or when you need complete isolation between tasks. It is also ideal when you need to bypass the limitations of Python’s GIL for true parallelism. Here are scenarios where multiprocessing is the better choice:\n",
        "\n",
        "#### 1. **CPU-Bound Tasks (e.g., Complex Computations, Data Processing)**\n",
        "   - **Example**: Numerical simulations, machine learning model training, image processing, and other tasks that require significant CPU resources.\n",
        "   - **Reasoning**: In CPU-bound tasks, Python's **GIL** prevents multiple threads from fully utilizing the CPU, as only one thread can execute Python bytecode at a time. Using multiprocessing, each process runs in its own Python interpreter with its own memory space, enabling true parallel execution across multiple CPU cores.\n",
        "\n",
        "#### 2. **Memory Isolation**\n",
        "   - **Example**: Tasks that need to run in complete isolation from each other for safety or stability reasons (e.g., running untrusted code or different versions of a service).\n",
        "   - **Reasoning**: Since processes have their own separate memory spaces, one process cannot directly affect another. This isolation is useful for security or stability, where you don’t want one task to accidentally corrupt the memory of another.\n",
        "\n",
        "#### 3. **Avoiding GIL Limitations**\n",
        "   - **Example**: Tasks where you want to fully utilize all available CPU cores for parallel computation, such as when performing Monte Carlo simulations or large-scale data analysis.\n",
        "   - **Reasoning**: The GIL limits Python threads in CPU-bound tasks. Multiprocessing runs separate Python processes, so each process can use a different core, making it ideal for tasks that are computationally expensive and benefit from parallelization.\n",
        "\n",
        "#### 4. **Heavy Parallel Data Processing**\n",
        "   - **Example**: Processing large datasets where each chunk of the data can be processed independently (e.g., splitting a dataset into chunks for parallel processing on multiple CPUs).\n",
        "   - **Reasoning**: Multiprocessing allows you to distribute the load across multiple processes and CPUs, helping to significantly reduce processing time for large datasets. Each process works on a separate subset of data, and inter-process communication can be done using queues or shared memory if needed.\n",
        "\n",
        "#### 5. **Long-Running Independent Tasks**\n",
        "   - **Example**: Running parallel tasks that take a long time to complete, like data conversion, large-scale web scraping, or rendering large images.\n",
        "   - **Reasoning**: In multiprocessing, each process is independent, which means that one process's failure won’t necessarily affect others. This makes multiprocessing suitable for long-running, independent tasks that can be distributed without dependency on other tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary: When to Choose Multithreading vs. Multiprocessing\n",
        "\n",
        "| **Scenario**                        | **Multithreading**                          | **Multiprocessing**                           |\n",
        "|-------------------------------------|---------------------------------------------|----------------------------------------------|\n",
        "| **I/O-bound tasks**                | Preferred (e.g., network requests, file I/O) | Not ideal unless there's a lot of inter-process communication needed |\n",
        "| **CPU-bound tasks**                | Less effective due to GIL                   | Preferred (utilizes multiple cores)           |\n",
        "| **Shared memory needs**            | Preferred (easy data sharing between threads) | More complex (requires IPC mechanisms like queues) |\n",
        "| **Low overhead tasks**             | Preferred (threads are lighter)             | Heavier (each process has its own memory)     |\n",
        "| **Heavy computation or data processing** | Not ideal (due to GIL)                     | Preferred (parallelization across cores)      |\n",
        "| **Memory isolation or safety**     | Not ideal (shared memory space)             | Preferred (processes are isolated)            |\n",
        "\n",
        "Ultimately, the choice depends on the nature of the task. If you need to handle many lightweight, I/O-bound tasks and can share memory easily, multithreading is the way to go. If you're dealing with computationally intensive tasks or need memory isolation, multiprocessing is the more appropriate choice."
      ],
      "metadata": {
        "id": "LgpcUxB_BmKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 2.Describe what a process pool is and how it helps in managing multiple processes efficiently."
      ],
      "metadata": {
        "id": "jBHAwYv_ptAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **process pool** is a collection of worker processes that are pre-allocated and managed for performing tasks concurrently. The concept is used primarily in environments where multiple tasks can be executed in parallel, especially when tasks are CPU-bound, and it's beneficial to distribute them across multiple processes.\n",
        "\n",
        "### Key Features of a Process Pool:\n",
        "1. **Pre-Allocated Workers**: Instead of creating a new process for each task, which can be inefficient, a pool of processes is created ahead of time. This means that there are a set number of worker processes available to handle incoming tasks.\n",
        "\n",
        "2. **Task Queue**: Tasks are placed in a queue, and available workers from the pool take on these tasks as they finish their current jobs. This allows for a managed workload without overwhelming the system with too many simultaneous processes.\n",
        "\n",
        "3. **Resource Management**: The number of worker processes in the pool is typically limited, which prevents overloading the system. For example, a system with 4 CPU cores may have a pool of 4 processes, with each process being assigned a separate task.\n",
        "\n",
        "4. **Efficiency**: By reusing workers and avoiding the overhead of creating and destroying processes frequently, process pools can greatly reduce system resources used for task management. This can make parallel computing more scalable and efficient.\n",
        "\n",
        "### How it Helps in Managing Multiple Processes Efficiently:\n",
        "1. **Reduced Overhead**: Creating and destroying processes is an expensive operation, especially in systems with limited resources. With a process pool, the overhead of process creation is avoided, and workers can be reused for multiple tasks, improving overall performance.\n",
        "\n",
        "2. **Load Balancing**: The pool manages the distribution of tasks across available workers, ensuring that work is balanced and that no worker is overwhelmed with too many tasks while others remain idle.\n",
        "\n",
        "3. **Parallel Execution**: A process pool enables multiple tasks to be executed in parallel, fully utilizing available CPU cores or processors. This is especially useful for CPU-bound operations that can be divided into independent units of work.\n",
        "\n",
        "4. **Control Over System Resources**: By limiting the number of active processes in the pool, you can control resource usage, preventing the system from being overwhelmed with too many processes running at once. This helps avoid issues like excessive context switching or running out of system resources.\n",
        "\n",
        "5. **Fault Tolerance**: If a worker process fails (e.g., due to an error), the pool can replace it with a new worker, ensuring that the system continues to process tasks without major disruptions.\n",
        "\n",
        "### Example: Python's `multiprocessing.Pool`\n",
        "\n",
        "In Python, for example, the `multiprocessing` module provides a `Pool` class that allows you to manage a pool of worker processes easily. Here's a simple example:\n",
        "\n",
        "```python\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(4) as pool:  # Create a pool with 4 processes\n",
        "        results = pool.map(square, range(10))  # Distribute tasks to workers\n",
        "    print(results)\n",
        "```\n",
        "\n",
        "In this example, the `Pool` creates a pool of 4 worker processes, and the `map` method distributes the task of squaring each number in the range [0, 9] across the workers in the pool. The process pool manages task distribution and parallelism automatically.\n",
        "\n",
        "### In Summary:\n",
        "A process pool efficiently manages multiple concurrent tasks by:\n",
        "- Reusing a fixed number of worker processes.\n",
        "- Distributing tasks dynamically among workers.\n",
        "- Minimizing the overhead of process creation and destruction.\n",
        "- Ensuring better resource utilization and system stability when performing parallel computations.\n",
        "\n",
        "This makes process pools particularly useful in scenarios where there is a need to perform many independent, CPU-bound tasks concurrently, like data processing, image processing, or any computationally intensive workload."
      ],
      "metadata": {
        "id": "fLmA4n09BquV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 3.Explain what a process pool is and why it is used in Python programs."
      ],
      "metadata": {
        "id": "KJibBiWJqAlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A process pool is a collection of worker processes that can be used to execute tasks concurrently in parallel. In Python, a process pool is typically used to manage and control multiple processes to perform parallel computations, especially in scenarios where the tasks are CPU-bound and would benefit from being distributed across multiple processor cores.\n",
        "\n",
        "Why is a Process Pool Used in Python?\n",
        "Python provides two primary ways to achieve parallelism:\n",
        "\n",
        "Thread-based parallelism (threading module) — useful for I/O-bound tasks.\n",
        "Process-based parallelism (multiprocessing module) — useful for CPU-bound tasks.\n",
        "For CPU-bound tasks, a process pool is preferable over threading due to Python’s Global Interpreter Lock (GIL). The GIL restricts threads to execute Python bytecode one at a time, limiting the effectiveness of threading for multi-core CPUs when tasks involve intensive CPU computations. Processes, on the other hand, run in separate memory spaces, each with its own Python interpreter and GIL, so they can fully utilize multiple CPU cores.\n",
        "\n",
        "Key Points About Process Pools in Python:\n",
        "Parallel Execution:\n",
        "\n",
        "A process pool allows tasks to be distributed among multiple processes, so they can be run concurrently on different CPU cores.\n",
        "Efficient Resource Management:\n",
        "\n",
        "Creating and managing processes manually can be cumbersome. A process pool abstracts away the management of individual processes, making it easier to submit and retrieve tasks.\n",
        "Scalability:\n",
        "\n",
        "By using a process pool, a program can scale easily to utilize all available CPU cores. It can also manage a large number of tasks without needing to manually create and track individual processes.\n",
        "Task Distribution:\n",
        "\n",
        "Tasks (usually functions) can be distributed to the workers in the pool, which execute them in parallel and return the results when finished.\n",
        "How to Use a Process Pool in Python:\n",
        "Python's multiprocessing module provides a Pool class, which is commonly used to create a process pool.\n",
        "\n",
        "Example:\n",
        "\n"
      ],
      "metadata": {
        "id": "42gLuAfeC5tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Define a function that will be executed in parallel\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a pool with 4 worker processes\n",
        "    with multiprocessing.Pool(processes=4) as pool:\n",
        "        # Map the function `square` to a list of numbers [1, 2, 3, 4, 5]\n",
        "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "\n",
        "    # Print the results\n",
        "    print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGQcjxEXDka3",
        "outputId": "502e4bb9-406c-4166-fe1b-9ee82b18e2ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Features of multiprocessing.Pool:\n",
        "pool.map(func, iterable):\n",
        "\n",
        "A parallel version of the built-in map function, where func is applied to each item in iterable. It automatically distributes the tasks to the worker processes in the pool and collects the results.\n",
        "pool.apply(func, args):\n",
        "\n",
        "Used to apply a function to a single argument in parallel, similar to how apply works in a single-process scenario, but it can be done across different processes.\n",
        "pool.apply_async(func, args):\n",
        "\n",
        "Asynchronous version of apply. It returns a result object that you can use to check the status of the task or retrieve the result once it’s finished.\n",
        "pool.close() and pool.join():\n",
        "\n",
        "close() prevents any more tasks from being submitted to the pool, and join() waits for all the worker processes to finish executing.\n",
        "Benefits of Using Process Pools:\n",
        "Increased Performance: For CPU-bound tasks, using multiple processes can dramatically speed up the execution by utilizing multiple cores of the CPU.\n",
        "Simplified Management: The process pool handles the creation, scheduling, and cleanup of worker processes automatically.\n",
        "Parallelism and Concurrency: It allows you to run many tasks concurrently, which is important in scenarios like simulations, heavy computations, or large data processing.\n",
        "Better CPU Utilization: Unlike threads, processes can run on different CPU cores without being limited by the GIL.\n",
        "When to Use a Process Pool?\n",
        "CPU-bound tasks: When you have tasks that require heavy computation (e.g., data processing, numerical simulations), using a process pool can take advantage of multiple CPU cores.\n",
        "Task parallelism: When you have many independent tasks that can be executed in parallel (e.g., processing chunks of data, running independent simulations).\n",
        "When Not to Use a Process Pool?\n",
        "I/O-bound tasks: If the tasks are waiting for I/O operations (e.g., file I/O, network calls), threads or asynchronous programming (asyncio) might be a better option than processes.\n",
        "Overhead Considerations: If the overhead of starting processes is greater than the benefits of parallelism, a process pool might not be worth it. For example, when the tasks are very small or quick.\n",
        "Summary\n",
        "A process pool in Python, provided by the multiprocessing.Pool class, allows you to run multiple processes in parallel, which is especially useful for CPU-bound tasks that can take full advantage of multi-core processors. It simplifies the management of parallel processes and improves performance by distributing the work across available CPU cores.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gLtewgWUD0-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 4.Write a Python program using multithreadng where one thread adds numbers to a list,and another thread removes numbers from list.Implement a mechanism to avoid race conditions using threading.Lock.\n"
      ],
      "metadata": {
        "id": "JVcHj_VLqQPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared resource (the list)\n",
        "numbers_list = []\n",
        "\n",
        "# Lock to ensure thread safety while modifying the shared resource\n",
        "lock = threading.Lock()\n",
        "\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(0.1)  # Simulate some delay in adding numbers\n",
        "        with lock:  # Ensure exclusive access to the list\n",
        "            numbers_list.append(i)\n",
        "            print(f\"Added {i} to the list.\")\n",
        "\n",
        "def remove_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(0.2)  # Simulate some delay in removing numbers\n",
        "        with lock:  # Ensure exclusive access to the list\n",
        "            if numbers_list:\n",
        "                removed = numbers_list.pop(0)\n",
        "                print(f\"Removed {removed} from the list.\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "\n",
        "def main():\n",
        "    # Create threads\n",
        "    add_thread = threading.Thread(target=add_numbers)\n",
        "    remove_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "    # Start threads\n",
        "    add_thread.start()\n",
        "    remove_thread.start()\n",
        "\n",
        "    # Wait for both threads to complete\n",
        "    add_thread.join()\n",
        "    remove_thread.join()\n",
        "\n",
        "    # Final state of the list\n",
        "    print(f\"Final list: {numbers_list}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4U9CIo_EW4l",
        "outputId": "8f044b73-285a-4587-b5dc-88ee77856335"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 0 to the list.\n",
            "Removed 0 from the list.\n",
            "Added 1 to the list.\n",
            "Added 2 to the list.\n",
            "Removed 1 from the list.\n",
            "Added 3 to the list.\n",
            "Added 4 to the list.\n",
            "Removed 2 from the list.\n",
            "Added 5 to the list.\n",
            "Added 6 to the list.\n",
            "Removed 3 from the list.\n",
            "Added 7 to the list.\n",
            "Added 8 to the list.\n",
            "Removed 4 from the list.\n",
            "Added 9 to the list.\n",
            "Removed 5 from the list.\n",
            "Removed 6 from the list.\n",
            "Removed 7 from the list.\n",
            "Removed 8 from the list.\n",
            "Removed 9 from the list.\n",
            "Final list: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 5.Describe the methods and tools available in Python for safety sharing data between threads and processes."
      ],
      "metadata": {
        "id": "RvI-DAhz-pWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, ensuring safe data sharing between threads and processes is essential to prevent issues such as race conditions, data corruption, or deadlocks. Python provides several methods and tools to facilitate safe sharing of data between threads and processes. These include synchronization primitives, shared memory objects, and communication mechanisms. Here’s a breakdown of the key methods and tools:\n",
        "\n",
        "1. Threading: Synchronization Tools for Threads\n",
        "Since Python threads share the same memory space, the main concern when working with threads is ensuring that data is not accessed concurrently in a way that causes inconsistencies. The following tools are provided by Python’s threading module:\n",
        "\n",
        "Locks:\n",
        "\n",
        "threading.Lock(): A simple locking mechanism that prevents other threads from accessing a particular piece of code or resource until the lock is released.\n"
      ],
      "metadata": {
        "id": "viHlDQnwFKgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "shared_data = 0\n",
        "\n",
        "def increment():\n",
        "    global shared_data\n",
        "    with lock:\n",
        "        shared_data += 1\n"
      ],
      "metadata": {
        "id": "aSp8ciH0FShF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RLocks (Reentrant Locks):\n",
        "\n",
        "threading.RLock(): A reentrant lock allows a thread to acquire the lock multiple times. This is useful when the thread might need to call a function that tries to acquire the same lock again.\n",
        "Example:\n",
        "\n"
      ],
      "metadata": {
        "id": "8p-jQOn6EwIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rlock = threading.RLock()\n"
      ],
      "metadata": {
        "id": "FzNvJjp8Fs9m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semaphores:\n",
        "\n",
        "threading.Semaphore(): A semaphore is a counter that can be used to limit access to a resource or to coordinate a group of threads."
      ],
      "metadata": {
        "id": "kgLA3-FbFx0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semaphore = threading.Semaphore(2)  # Only 2 threads can access the resource at once.\n"
      ],
      "metadata": {
        "id": "Pm4sNeARFdkA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Event Objects:\n",
        "\n",
        "threading.Event(): An event is a synchronization primitive used for signaling between threads. One thread sets the event, while other threads wait for the event to be set before proceeding."
      ],
      "metadata": {
        "id": "1Fx37ThXF9t4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event = threading.Event()\n",
        "\n",
        "def waiter():\n",
        "    event.wait()  # Wait for the event to be set\n",
        "    print(\"Event triggered!\")\n",
        "\n",
        "def trigger():\n",
        "    event.set()  # Signal that the event has occurred\n"
      ],
      "metadata": {
        "id": "CgHboW_oGJNG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Condition Variables:\n",
        "\n",
        "threading.Condition(): This is used to allow threads to wait for some condition to be met before continuing."
      ],
      "metadata": {
        "id": "ghp2NT-dGWmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condition = threading.Condition()\n",
        "\n",
        "def producer():\n",
        "    with condition:\n",
        "        # Produce something and notify consumer\n",
        "        condition.notify()\n",
        "\n",
        "def consumer():\n",
        "    with condition:\n",
        "        condition.wait()  # Wait until producer signals\n",
        "        print(\"Consumer processed data.\")\n"
      ],
      "metadata": {
        "id": "jUUhT5IbGX1x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Multiprocessing: Communication and Shared Memory\n",
        "In the case of processes, since each process has its own memory space, sharing data between processes requires inter-process communication (IPC) mechanisms. The multiprocessing module provides several tools to manage shared data:\n",
        "\n",
        "Shared Memory (Value and Array):\n",
        "\n",
        "multiprocessing.Value(): A way to create a single shared value across processes (e.g., multiprocessing.Value('i', 0) creates an integer with value 0).\n",
        "multiprocessing.Array(): A way to create a shared array that can be accessed by multiple processes."
      ],
      "metadata": {
        "id": "Yy7rFBx6G0Hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Value, Process\n",
        "\n",
        "shared_value = Value('i', 0)\n",
        "\n",
        "def increment(shared_value):\n",
        "    with shared_value.get_lock():  # Acquire lock to safely modify shared value\n",
        "        shared_value.value += 1\n",
        "\n",
        "p = Process(target=increment, args=(shared_value,))\n",
        "p.start()\n",
        "p.join()\n",
        "print(shared_value.value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fsUDxlgG9Rv",
        "outputId": "d711c50e-062c-48df-f2e0-dec78b18bb31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manager Objects:\n",
        "\n",
        "multiprocessing.Manager(): A manager object is a way to create shared objects (like lists, dictionaries, etc.) that can be accessed by multiple processes. This involves creating proxy objects that synchronize access to the shared objects.\n"
      ],
      "metadata": {
        "id": "LQ0yl-8yHFus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Manager, Process\n",
        "\n",
        "def worker(shared_dict):\n",
        "    shared_dict['key'] = 'value'\n",
        "\n",
        "manager = Manager()\n",
        "shared_dict = manager.dict()\n",
        "\n",
        "p = Process(target=worker, args=(shared_dict,))\n",
        "p.start()\n",
        "p.join()\n",
        "print(shared_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kj30ZT-HHLo",
        "outputId": "463a323d-5f10-4a07-8df6-f816ced3e572"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'key': 'value'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Queues and Pipes (for Communication):\n",
        "\n",
        "multiprocessing.Queue(): A thread-safe FIFO queue used for sending data between processes.\n",
        "multiprocessing.Pipe(): A pipe provides a two-way communication channel between processes.\n"
      ],
      "metadata": {
        "id": "yxR5cBcTHPHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def producer(q):\n",
        "    q.put('item')\n",
        "\n",
        "def consumer(q):\n",
        "    item = q.get()\n",
        "    print(item)\n",
        "\n",
        "q = Queue()\n",
        "p1 = Process(target=producer, args=(q,))\n",
        "p2 = Process(target=consumer, args=(q,))\n",
        "\n",
        "p1.start()\n",
        "p2.start()\n",
        "p1.join()\n",
        "p2.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8qhz0SBOAAT",
        "outputId": "0daa2041-629d-4400-bea2-39c83ca73f6a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Other Useful Tools\n",
        "Thread-safe Collections (from queue module):\n",
        "\n",
        "queue.Queue(), queue.LifoQueue(), queue.PriorityQueue(): These are thread-safe queues that allow for communication between threads."
      ],
      "metadata": {
        "id": "ug-gWcOOOFXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import queue\n",
        "q = queue.Queue()\n",
        "q.put(1)\n",
        "value = q.get()\n"
      ],
      "metadata": {
        "id": "ejjsmEVKOQTW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thread-local Storage:\n",
        "\n",
        "threading.local(): This is a way to store data that is specific to the current thread. Each thread has its own instance of the data."
      ],
      "metadata": {
        "id": "7bp3HCiWOUrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread_local = threading.local()\n",
        "\n",
        "def process():\n",
        "    thread_local.data = \"Thread-specific data\"\n",
        "    print(thread_local.data)\n"
      ],
      "metadata": {
        "id": "kXNP2brwOZtp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 6.Discuss why it's crucial to handle exceptions in concurrent programs and the techniques available for doing so."
      ],
      "metadata": {
        "id": "XSQFxOQ2-5Oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling exceptions in concurrent programs is crucial because of the complexity and unpredictability inherent in managing multiple tasks that run in parallel. If exceptions are not properly managed, they can lead to incomplete or inconsistent state, crashes, or even subtle bugs that are difficult to diagnose and reproduce. Concurrent programs introduce a variety of challenges, including race conditions, deadlocks, and task dependencies, all of which can result in errors that need to be caught and handled appropriately.\n",
        "\n",
        "Why Exception Handling is Crucial in Concurrent Programs\n",
        "Race Conditions and Non-Determinism: In concurrent programs, multiple threads or processes often operate on shared data. If an exception occurs in one thread, it can interfere with other threads' operations, potentially leaving shared resources in an inconsistent or corrupted state. Proper exception handling ensures that the program can recover gracefully and maintain its integrity even when things go wrong.\n",
        "\n",
        "Thread Isolation: If an exception occurs in one thread, it might not propagate to other threads. Without careful exception handling, an exception in one thread could be silently ignored or could cause the thread to terminate unexpectedly, leaving other threads unaware of the failure. Managing exceptions across threads ensures that failures are detected and handled in a way that does not cause unpredictable behavior in other parts of the program.\n",
        "\n",
        "Deadlocks and Resource Leaks: Exceptions during resource acquisition (e.g., acquiring locks, allocating memory) in concurrent programs can leave resources in an inconsistent or leaked state. This can lead to deadlocks or memory leaks if resources are not properly released. Exception handling ensures that resources are always cleaned up, even in the event of a failure.\n",
        "\n",
        "Error Propagation: In a concurrent system, errors might be raised in one thread but need to be communicated back to the main thread or to other threads for appropriate action. Without proper exception handling, error propagation becomes difficult to manage and track.\n",
        "\n",
        "Techniques for Handling Exceptions in Concurrent Programs\n",
        "Several techniques are commonly used to handle exceptions in concurrent programming environments. These techniques are designed to ensure that errors are caught, reported, and managed in a way that maintains system stability and consistency.\n",
        "\n",
        "1. Try-Catch Blocks (Exception Wrapping)\n",
        "In multi-threaded environments, individual threads can catch exceptions within their own execution flow. When an exception occurs in a thread, it can be caught using a try-catch block.\n",
        "However, catching the exception inside the thread doesn’t automatically propagate it to the calling code (e.g., the main thread), so it's often useful to \"wrap\" the exception in a custom object or use callback mechanisms to propagate it to other parts of the program.\n"
      ],
      "metadata": {
        "id": "A3ZMBLocUy41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def task_function():\n",
        "    raise Exception(\"Something went wrong\")\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(task_function)\n",
        "    try:\n",
        "        future.result()  # Will raise an exception if the task fails\n",
        "    except Exception as e:\n",
        "        print(f\"Task failed with exception: {e}\")\n"
      ],
      "metadata": {
        "id": "IJR5UnSdSVtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 7.Create a Python that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.Use concurrent.futures.ThreadPoolExecuter to mmanage the threads."
      ],
      "metadata": {
        "id": "BjS6mPti_k3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial of a number\n",
        "def calculate_factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "# Main function to manage the thread pool\n",
        "def main():\n",
        "    # Use ThreadPoolExecutor to manage the threads\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Submit the tasks to the thread pool for numbers 1 to 10\n",
        "        results = executor.map(calculate_factorial, range(1, 11))\n",
        "\n",
        "        # Output the results\n",
        "        for number, factorial in zip(range(1, 11), results):\n",
        "            print(f\"Factorial of {number} is {factorial}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLhLpP9gU_hA",
        "outputId": "cda3d042-0fa9-4a65-b853-db7e19d7b736"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 1 is 1\n",
            "Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 8.Create a Python program  that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel.Measure the time taken to perform this computation using a pool of different sizes(eg.,2,4,8,processes)."
      ],
      "metadata": {
        "id": "nVnFo4QUADLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def compute_square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure the time taken using different pool sizes\n",
        "def measure_time(pool_size):\n",
        "    # Create a pool of workers with the specified pool size\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        # Measure the start time\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Use map to compute the square of numbers from 1 to 10\n",
        "        results = pool.map(compute_square, range(1, 11))\n",
        "\n",
        "        # Measure the end time\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Calculate the time taken\n",
        "        time_taken = end_time - start_time\n",
        "        return time_taken, results\n",
        "\n",
        "def main():\n",
        "    pool_sizes = [2, 4, 8]  # Different pool sizes to test\n",
        "\n",
        "    for pool_size in pool_sizes:\n",
        "        print(f\"\\nUsing a pool of {pool_size} processes:\")\n",
        "\n",
        "        # Measure time taken and get the results\n",
        "        time_taken, results = measure_time(pool_size)\n",
        "\n",
        "        # Output the results and time taken\n",
        "        print(f\"Squares: {results}\")\n",
        "        print(f\"Time taken: {time_taken:.4f} seconds\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLYdRAWrVPp3",
        "outputId": "9908b965-13e5-460b-f86a-5392fe1707ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using a pool of 2 processes:\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0034 seconds\n",
            "\n",
            "Using a pool of 4 processes:\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0121 seconds\n",
            "\n",
            "Using a pool of 8 processes:\n",
            "Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.0125 seconds\n"
          ]
        }
      ]
    }
  ]
}